---
title: "Partial Identification in Blood Donation RDD Analysis"
subtitle: "Using Simulated Data for Package Demonstration"
author: "Karthik Rajkumar, Evan Rosenman, Romain Gauriot, Robert Slonim"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 3
    number_sections: true
vignette: >
  %\VignetteIndexEntry{Partial Identification in Blood Donation RDD Analysis}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
bibliography: references.bib
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 5,
  warning = FALSE,
  message = FALSE
)
```

# Introduction

The `rdpartial` package implements partial identification methods for regression discontinuity designs when units may manipulate the running variable. This vignette demonstrates the package functionality using **simulated blood donation data**, where potential donors near the hemoglobin cutoff may influence their readings.

Standard RDD estimators assume no manipulation in the running variable. When this assumption fails, estimates may be severely biased. The `rdpartial` package provides robust bounds on treatment effects that remain valid under various manipulation scenarios. The methodology is detailed in @rosenman2025donorsdeferralreturnbehavior.

## Methodology

The package addresses manipulation concerns by:

**Acknowledging manipulation uncertainty**: Rather than assuming no manipulation, the approach explicitly models manipulation intervals where units may influence their running variable values.

**Providing bounds**: Instead of point estimates that may be biased, the method delivers bounds that capture the range of plausible treatment effects under different manipulation scenarios.

**Ensuring robustness**: The bounds account for worst-case manipulation within the specified region. The bounds remain valid regardless of the exact manipulation pattern, provided manipulation does not exceed the assumed region boundaries.

# Package Installation and Setup

```{r installation, eval = FALSE}
# Install from GitHub (development version)
if (!requireNamespace("devtools", quietly = TRUE)) {
  install.packages("devtools")
}
devtools::install_github("rajkumarkarthik/rdpartial")
```

```{r libraries}
library(rdpartial)
library(dplyr)
library(ggplot2)
library(parallel)

# Set analysis parameters
set.seed(2021)
```

# Analysis Configuration

We begin by setting key parameters for our analysis. These can be modified to explore different scenarios or replicate specific results.

```{r parameters}
# Analysis settings
analysisGender  <- "F"  # Focus on female donors
cutoff          <- ifelse(analysisGender == "M", 13.5, 12.5)   # Hemoglobin threshold (g/dL)
cutoff_upper    <- ifelse(analysisGender == "M", 18.0, 17.0)   # Upper bound for analysis range

# Outcome and treatment variables
outcome_col     <- "comebackinnext12month"  # Binary: returned within 12 months
treatment_col   <- "accepted"               # Binary: 1 = accepted, 0 = deferred
treat_direction <- "decrease"               # Direction of treatment effect at cutoff

# Estimation parameters
poly_order      <- 1L                       # Local polynomial order
num_folds       <- 5L                       # Cross-validation folds for density estimation

# Parallel computing settings - memory-aware core allocation
n_cores <- min(4L, parallel::detectCores() - 1L)  # Cap at 4 cores for memory safety
```

## Defining Manipulation Regions

The primary input to `rdpartial` functions is the specification of manipulation intervals where units may influence their running variable values. The analysis tests multiple manipulation regions to assess robustness across different manipulation assumptions.

```{r manipulation_regions}
# Define candidate manipulation intervals
# These represent different assumptions about manipulation extent
if(analysisGender == 'F') {
  manip_regions <- list(
    c(cutoff - 0.1, cutoff),     # Narrow manipulation: 0.1 g/dL below cutoff
    c(cutoff - 0.2, cutoff),     # Moderate manipulation: 0.2 g/dL below cutoff  
    c(cutoff - 0.3, cutoff),     # Wide manipulation: 0.3 g/dL below cutoff
    c(cutoff - 0.4, cutoff),     # Very wide manipulation: 0.4 g/dL below cutoff
    c(cutoff - 0.1, cutoff + 0.1), # Symmetric narrow manipulation
    c(cutoff - 0.2, cutoff + 0.1), # Asymmetric moderate manipulation
    c(cutoff - 0.3, cutoff + 0.1), # Asymmetric wide manipulation
    c(cutoff - 0.4, cutoff + 0.1), # Asymmetric very wide manipulation
    c(cutoff - 0.1, cutoff + 0.2), # Extended upper manipulation
    c(cutoff - 0.2, cutoff + 0.2), # Extended moderate manipulation
    c(cutoff - 0.3, cutoff + 0.2), # Extended wide manipulation
    c(cutoff - 0.4, cutoff + 0.2)  # Extended very wide manipulation
  )
} else if(analysisGender == 'M') {
  # For males, use a single manipulation region based on empirical analysis
  manip_regions <- list(c(cutoff - 0.6, cutoff + 0.1))
}

cat("Testing", length(manip_regions), "manipulation regions for", 
    ifelse(analysisGender == 'F', "women", "men"), "\n")
```

# Data Preparation

The analysis uses **simulated blood donation data** that replicates the structure of the original study. The simulated data is publicly available for demonstration purposes in the study since the original study data consists of confidential medical records.

```{r data_loading}
# Load simulated data from GitHub repository
# NOTE: This is simulated data, not the original confidential medical records
data_url <- "https://raw.githubusercontent.com/rajkumarkarthik/rdpartial-data/main/Rosenman.et.al.2025_simulated_data_all.csv"

cat("Loading simulated data from GitHub repository...\n")
raw <- read.csv(data_url)

# Extract and clean the relevant dataset
dat <- raw %>%
  filter(gender == analysisGender,
         hlevel >= 0, 
         hlevel <= cutoff_upper) %>%        # Restrict to analysis range
  mutate(
    hlevel = round(hlevel, 1),              # Round hemoglobin to nearest 0.1
    age    = ifelse(is.na(age), mean(age, na.rm = TRUE), age)  # Impute missing age
  )

# Additional filtering for male analysis (exclude plasma donations)
if(analysisGender == 'M') {
  dat <- dat %>%
    filter(donationtype != 'Plasma')
}

# For time-to-next-donation outcome, filter to those with valid follow-up
if (outcome_col == "Ndaytonextdonation") {
  dat <- dat %>%
    filter(!is.na(Ndaytonextdonation), !is.infinite(Ndaytonextdonation))
}

cat("Analysis dataset: ", nrow(dat), "observations\n")
cat("Outcome variable:", outcome_col, "\n")
cat("Treatment variable:", treatment_col, "\n")
```

# Data Preprocessing

The analysis requires constructing a histogram of the running variable and computing tricubic kernel weights for local polynomial estimation.

```{r preliminaries}
# Create histogram for density estimation
hist_df <- dat %>%
  count(hlevel, name = "freq") %>%
  arrange(hlevel) %>%
  rename(x = hlevel)

cat("Histogram created with", nrow(hist_df), "unique hemoglobin values\n")

# Compute tricubic kernel weights
# These weights give more influence to observations closer to the cutoff
ix_left   <- dat$hlevel < cutoff
ix_right  <- !ix_left

w_kernel <- numeric(nrow(dat))
w_kernel[ix_left]  <- rdpartial:::.tricube(cutoff - dat$hlevel[ix_left])
w_kernel[ix_right] <- rdpartial:::.tricube(dat$hlevel[ix_right] - cutoff)

cat("Kernel weights computed for", sum(ix_left), "left-side and", 
    sum(ix_right), "right-side observations\n")
```

# Estimation

The estimation procedure tests each manipulation region, with automatic spline specification selection via cross-validation. Parallel processing is employed for computational efficiency.

```{r analysis_function}
# Define analysis function for a single manipulation region
analyze_region <- function(j, region, hist_df, dat, cutoff, num_folds, 
                          w_kernel, outcome_col, treatment_col, poly_order, 
                          treat_direction) {
  
  # Density estimation to obtain non-manipulated counts
  dens_out <- rdpartial:::.density_estimation(
    hist_df      = hist_df,
    manip_region = region,
    cutoff       = cutoff,
    knot_options = 3:8,
    mod_types    = "smooth",
    num_folds    = num_folds,
    make_plot    = FALSE  # Disable plots during parallel processing to save memory
  )
  
  # Partial-identification bounds computation (fuzzy design)
  bnds <- rdpartial::bounds_fuzzy(
    x               = dat$hlevel,
    y               = dat[[outcome_col]],
    z               = dat[[treatment_col]],
    cutoff          = cutoff,
    true_counts     = dens_out$counts,
    weights         = w_kernel,
    poly_order      = poly_order,
    treat_direction = treat_direction,
    bounds          = "both",
    runVarPlots     = FALSE,  # Disable plots during parallel processing to save memory
    ylab            = outcome_col,
    xlab            = "Hemoglobin Level (g/dL)"
  )
  
  # Return comprehensive results
  list(
    region_id    = j,
    bounds       = bnds,
    avg_cv_sse   = dens_out$avg_cv_sse,
    avg_sse      = dens_out$avg_sse,
    knots        = dens_out$knots
  )
}

# Define analysis function with plots for optimal region only
analyze_region_with_plots <- function(j, region, hist_df, dat, cutoff, num_folds, 
                                     w_kernel, outcome_col, treatment_col, poly_order, 
                                     treat_direction) {
  
  # Density estimation with plots enabled
  dens_out <- rdpartial:::.density_estimation(
    hist_df      = hist_df,
    manip_region = region,
    cutoff       = cutoff,
    knot_options = 3:8,
    mod_types    = "smooth",
    num_folds    = num_folds,
    make_plot    = TRUE  # Enable plots for optimal region
  )
  
  # Partial-identification bounds computation with plots
  bnds <- rdpartial::bounds_fuzzy(
    x               = dat$hlevel,
    y               = dat[[outcome_col]],
    z               = dat[[treatment_col]],
    cutoff          = cutoff,
    true_counts     = dens_out$counts,
    weights         = w_kernel,
    poly_order      = poly_order,
    treat_direction = treat_direction,
    bounds          = "both",
    runVarPlots     = TRUE,  # Enable plots for optimal region
    ylab            = outcome_col,
    xlab            = "Hemoglobin Level (g/dL)"
  )
  
  # Return comprehensive results with plots
  list(
    region_id    = j,
    bounds       = bnds,
    avg_cv_sse   = dens_out$avg_cv_sse,
    avg_sse      = dens_out$avg_sse,
    knots        = dens_out$knots,
    density_plot = dens_out$plot
  )
}
```

```{r parallel_analysis}
cat("Starting parallel analysis across", length(manip_regions), "manipulation regions...\n")
cat("Using", n_cores, "cores for parallel computation\n\n")

# Set up progress reporting
start_time <- Sys.time()

# Parallel execution with progress updates
if(.Platform$OS.type == "windows") {
  # Use sequential processing on Windows (with progress bar)
  cat("Windows detected: using sequential processing with progress bar\n")
  
  pb <- txtProgressBar(min = 0, max = length(manip_regions), style = 3)
  results <- vector("list", length(manip_regions))
  
  for(j in seq_along(manip_regions)) {
    region <- manip_regions[[j]]
    cat(sprintf("\n• Processing Region %d: [%0.2f, %0.2f]\n", j, region[1], region[2]))
    
    results[[j]] <- analyze_region(j, region, hist_df, dat, cutoff, num_folds, 
                                  w_kernel, outcome_col, treatment_col, 
                                  poly_order, treat_direction)
    
    setTxtProgressBar(pb, j)
  }
  close(pb)
  
} else {
  # Use parallel processing on Unix-like systems
  cat("Unix-like system detected: using parallel processing\n")
  
  # Display progress by printing region information
  for(j in seq_along(manip_regions)) {
    region <- manip_regions[[j]]
    cat(sprintf("• Queued Region %d: [%0.2f, %0.2f]\n", j, region[1], region[2]))
  }
  cat("\nExecuting parallel analysis...\n")
  
  # Execute in parallel
  results <- parallel::mclapply(seq_along(manip_regions), function(j) {
    analyze_region(j, manip_regions[[j]], hist_df, dat, cutoff, num_folds, 
                  w_kernel, outcome_col, treatment_col, poly_order, treat_direction)
  }, mc.cores = n_cores)
}

end_time <- Sys.time()
cat(sprintf("\nAnalysis completed in %.2f minutes\n", 
           as.numeric(difftime(end_time, start_time, units = "mins"))))
```

# Results

The following sections present bounds estimates across manipulation regions and identify the optimal specification based on cross-validation performance.

```{r results_summary}
# Extract bounds matrix - handle simplified bounds structure
bounds_mat <- do.call(rbind, lapply(results, function(x) x$bounds))
rownames(bounds_mat) <- paste0("R", seq_along(manip_regions))

cat("Partial-identification bounds across manipulation regions:\n")
print(round(bounds_mat, 4))

# Extract model selection diagnostics  
sse_tbl <- do.call(rbind, lapply(results, function(x)
  c(cv_sse = x$avg_cv_sse, sse = x$avg_sse, knots = x$knots)))
rownames(sse_tbl) <- paste0("R", seq_along(manip_regions))

cat("\nSpline cross-validation diagnostics:\n")
print(round(sse_tbl, 4))

# Identify optimal manipulation region (lowest cross-validation error)
optIndex <- which.min(sse_tbl[, "cv_sse"])
opt_region <- manip_regions[[optIndex]]

cat(sprintf("\nOptimal manipulation region: R%d [%.2f, %.2f]\n", 
           optIndex, opt_region[1], opt_region[2]))
cat(sprintf("Cross-validation SSE: %.4f\n", sse_tbl[optIndex, "cv_sse"]))
cat(sprintf("Optimal bounds: [%.4f, %.4f]\n", 
           bounds_mat[optIndex, "lower"], bounds_mat[optIndex, "upper"]))

# Generate plots only for optimal region to save memory during parallel processing
cat("\nGenerating diagnostic plots for optimal region...\n")
opt_results <- analyze_region_with_plots(optIndex, opt_region, hist_df, dat, cutoff, 
                                        num_folds, w_kernel, outcome_col, treatment_col, 
                                        poly_order, treat_direction)
```

# Visualization

The package generates diagnostic plots for density estimation, outcome analysis, and treatment assignment patterns.

```{r plots, fig.width=10, fig.height=12}
# Plot density estimation for optimal region
density_plot <- opt_results$density_plot +
  ggtitle(paste0('Density Estimation - Optimal Manipulation Region for ',
                ifelse(analysisGender == 'F', "Women", "Men"), 
                ': [', paste(round(opt_region, 2), collapse = ', '), ']')) +
  theme_minimal()

print(density_plot)

# Plot outcome variable
outcome_plot <- opt_results$bounds$yPlot +
  ggtitle("Outcome Analysis: Return Probability vs. Hemoglobin Level") +
  theme_minimal()

print(outcome_plot)

# Plot treatment variable  
treatment_plot <- opt_results$bounds$zPlot +
  ggtitle("Treatment Analysis: Acceptance Probability vs. Hemoglobin Level") +
  theme_minimal()

print(treatment_plot)
```

# Bootstrap Inference

Bootstrap confidence intervals are computed using the `bootstrap_bounds()` function, which resamples observations while preserving the running variable distribution.

```{r bootstrap_setup}
# Bootstrap parameters  
n_boot <- if (identical(Sys.getenv("CI"), "true")) 10 else 100  # Reduced for CI builds

cat("Computing bootstrap confidence intervals...\n")
cat(sprintf("Bootstrap replications: %d\n", n_boot))
cat(sprintf("Parallel cores: %d\n", n_cores))
cat("This may take several minutes...\n\n")
```

```{r bootstrap_analysis}
# Enhanced bootstrap with progress reporting
start_boot_time <- Sys.time()

# Display initial information
cat("Bootstrap analysis configuration:\n")
cat(sprintf("• Simulated dataset: %d observations (%s donors)\n", nrow(dat), 
           ifelse(analysisGender == 'F', "female", "male")))
cat(sprintf("• Manipulation regions: %d scenarios\n", length(manip_regions)))
cat(sprintf("• Bootstrap replications: %d\n", n_boot))
cat(sprintf("• Parallel processing: %s\n", 
           ifelse(.Platform$OS.type != "windows", "enabled", "disabled (Windows)")))

if(.Platform$OS.type != "windows") {
  cat("Note: Progress updates are limited during parallel bootstrap execution\n")
  cat("to avoid output conflicts. Please be patient...\n\n")
}

# Execute bootstrap with memory-aware parallel processing
# Note: Using the same memory-safe core limit as in the main analysis
bootBounds <- rdpartial::bootstrap_bounds(
  data            = dat,
  running_var     = 'hlevel',
  outcome         = outcome_col,
  treatment       = treatment_col,
  cutoff          = cutoff,
  manip_regions   = manip_regions,
  estimator       = 'fuzzy',
  n_boot          = n_boot,
  parallel        = (.Platform$OS.type != "windows"),
  n_cores         = n_cores,  # Uses the memory-safe core limit set earlier
  progress        = (.Platform$OS.type == "windows"),
  seed            = 2021
)

end_boot_time <- Sys.time()
boot_duration <- as.numeric(difftime(end_boot_time, start_boot_time, units = "mins"))

cat(sprintf("\nBootstrap analysis completed in %.2f minutes\n", boot_duration))
```

```{r bootstrap_results}
# Display bootstrap confidence intervals
cat("Bootstrap 95% Confidence Intervals:\n")
print(bootBounds)

# Enhanced results summary
cat("\nDetailed Bootstrap Results Summary:\n")
cat("====================================\n")

ci_matrix <- bootBounds$ci
for(i in seq_len(nrow(ci_matrix))) {
  region <- manip_regions[[i]]
  cat(sprintf("Region %d [%.2f, %.2f]: CI = [%.4f, %.4f], Width = %.4f\n",
             i, region[1], region[2], 
             ci_matrix[i, "lwr"], ci_matrix[i, "upr"],
             ci_matrix[i, "upr"] - ci_matrix[i, "lwr"]))
}

# Highlight optimal region results
opt_ci <- ci_matrix[optIndex, ]
cat(sprintf("\nOptimal Region Results (R%d):\n", optIndex))
cat(sprintf("• Manipulation interval: [%.2f, %.2f] g/dL\n", opt_region[1], opt_region[2]))
cat(sprintf("• Point bounds: [%.4f, %.4f]\n", 
           bounds_mat[optIndex, "lower"], bounds_mat[optIndex, "upper"]))
cat(sprintf("• 95%% CI: [%.4f, %.4f]\n", opt_ci["lwr"], opt_ci["upr"]))
cat(sprintf("• CI width: %.4f\n", opt_ci["upr"] - opt_ci["lwr"]))
```

# Implementation Notes

## Bounds Interpretation

The bounds matrix contains the range of plausible treatment effects under each manipulation scenario:

```{r example_interpretation, eval=FALSE}
# The bounds tell us the range of plausible effects
print(bounds_mat[optIndex, ])

# Bootstrap confidence intervals add uncertainty quantification
print(bootBounds$ci[optIndex, ])
```

Tight bounds excluding zero indicate robust identification of treatment effect direction and magnitude. Wide bounds or bounds including zero suggest substantial manipulation uncertainty or limited identification power.

## Parameter Selection

**Manipulation regions**: Specify intervals based on institutional knowledge of manipulation possibilities. Multiple specifications should be tested for robustness assessment.

**Computational parameters**: The `n_boot` parameter controls bootstrap replications (100-500 recommended), `knot_options` determines spline flexibility (3:8 typically sufficient), and `parallel` enables multicore processing on Unix systems.

**Data requirements**: The package expects numeric running variables, binary outcomes (0/1) for standard applications, and binary treatment indicators (0/1). Missing values should be handled prior to analysis.

# Performance

```{r performance_summary}
cat("Performance Summary:\n")
cat("===================\n")
cat(sprintf("Analysis duration: %.2f minutes\n", 
           as.numeric(difftime(end_time, start_time, units = "mins"))))
cat(sprintf("Bootstrap duration: %.2f minutes\n", boot_duration))
cat(sprintf("Total computation time: %.2f minutes\n", 
           as.numeric(difftime(end_boot_time, start_time, units = "mins"))))
cat(sprintf("Parallel cores utilized: %d\n", n_cores))
cat(sprintf("Bootstrap replications: %d\n", n_boot))
cat(sprintf("Manipulation regions tested: %d\n", length(manip_regions)))

if(.Platform$OS.type != "windows") {
  cat("\nParallel processing significantly reduced computation time.\n")
  cat("Sequential processing would require substantially longer.\n")
} else {
  cat("\nFor optimal performance on multi-core systems,\n")
  cat("consider running this analysis on Unix-like systems\n")
  cat("where parallel processing is fully supported.\n")
}
```

# Summary

This vignette demonstrates `rdpartial` package functionality for regression discontinuity designs with manipulation concerns. The package provides robust bounds estimation through density estimation, cross-validated model selection, and bootstrap inference. Key methodological features include explicit manipulation modeling, automatic spline specification selection, and parallel computational implementation.

# References

For more details on the theoretical foundations, see @rosenman2025donorsdeferralreturnbehavior. The package documentation provides additional technical details and examples for various use cases.
