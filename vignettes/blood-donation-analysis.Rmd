---
title: "Partial Identification in Blood Donation RDD Analysis"
subtitle: "Using Simulated Data for Package Demonstration"
author: "Karthik Rajkumar, Evan Rosenman, Romain Gauriot, Robert Slonim"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 3
    number_sections: true
vignette: >
  %\VignetteIndexEntry{Partial Identification in Blood Donation RDD Analysis}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
bibliography: references.bib
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 5,
  warning = FALSE,
  message = FALSE
)
```

# Introduction

The `rdpartial` package implements partial identification methods for regression discontinuity designs when units may manipulate the running variable. This vignette demonstrates the package functionality using **simulated blood donation data**, where potential donors near the hemoglobin cutoff may influence their readings.

Standard RDD estimators assume no manipulation in the running variable. When this assumption fails, estimates may be severely biased. The `rdpartial` package provides robust bounds on treatment effects that remain valid under various manipulation scenarios. The methodology is detailed in @rosenman2025donorsdeferralreturnbehavior.

## Methodology

The package addresses manipulation concerns by:

**Acknowledging manipulation uncertainty**: Rather than assuming no manipulation, the approach explicitly models manipulation intervals where units may influence their running variable values.

**Providing bounds**: Instead of point estimates that may be biased, the method delivers bounds that capture the range of plausible treatment effects under different manipulation scenarios.

**Ensuring robustness**: The bounds account for worst-case manipulation within the specified region. The bounds remain valid regardless of the exact manipulation pattern, provided manipulation does not exceed the assumed region boundaries.

# Package Installation and Setup

```{r installation, eval = FALSE}
# Install from GitHub (development version)
if (!requireNamespace("devtools", quietly = TRUE)) {
  install.packages("devtools")
}
devtools::install_github("rajkumarkarthik/rdpartial")
```

```{r libraries}
library(rdpartial)
library(dplyr)
library(ggplot2)
library(parallel)

# Set analysis parameters
set.seed(2021)
```

# Analysis Configuration

We begin by setting key parameters for our analysis. These can be modified to explore different scenarios or replicate specific results.

```{r parameters}
# Analysis settings
analysisGender  <- "F"  # Focus on female donors
cutoff          <- ifelse(analysisGender == "M", 13.5, 12.5)   # Hemoglobin threshold (g/dL)
cutoff_upper    <- ifelse(analysisGender == "M", 18.0, 17.0)   # Upper bound for analysis range

# Outcome and treatment variables
outcome_col     <- "comebackinnext12month"  # Binary: returned within 12 months
treatment_col   <- "accepted"               # Binary: 1 = accepted, 0 = deferred
treat_direction <- "decrease"               # Direction of treatment effect at cutoff

# Estimation parameters
poly_order      <- 1L                       # Local polynomial order
num_folds       <- 5L                       # Cross-validation folds for density estimation

# Parallel computing settings - memory-aware core allocation
n_cores <- min(4L, parallel::detectCores() - 1L)  # Cap at 4 cores for memory safety
```

## Defining Manipulation Regions

The primary input to `rdpartial` functions is the specification of manipulation intervals where units may influence their running variable values. The analysis tests multiple manipulation regions to assess robustness across different manipulation assumptions.

```{r manipulation_regions}
# Define candidate manipulation intervals
# These represent different assumptions about manipulation extent
if(analysisGender == 'F') {
  manip_regions <- list(
    c(cutoff - 0.1, cutoff),     # Narrow manipulation: 0.1 g/dL below cutoff
    c(cutoff - 0.2, cutoff),     # Moderate manipulation: 0.2 g/dL below cutoff  
    c(cutoff - 0.3, cutoff),     # Wide manipulation: 0.3 g/dL below cutoff
    c(cutoff - 0.4, cutoff),     # Very wide manipulation: 0.4 g/dL below cutoff
    c(cutoff - 0.1, cutoff + 0.1), # Symmetric narrow manipulation
    c(cutoff - 0.2, cutoff + 0.1), # Asymmetric moderate manipulation
    c(cutoff - 0.3, cutoff + 0.1), # Asymmetric wide manipulation
    c(cutoff - 0.4, cutoff + 0.1), # Asymmetric very wide manipulation
    c(cutoff - 0.1, cutoff + 0.2), # Extended upper manipulation
    c(cutoff - 0.2, cutoff + 0.2), # Extended moderate manipulation
    c(cutoff - 0.3, cutoff + 0.2), # Extended wide manipulation
    c(cutoff - 0.4, cutoff + 0.2)  # Extended very wide manipulation
  )
} else if(analysisGender == 'M') {
  # For males, use a single manipulation region based on empirical analysis
  manip_regions <- list(c(cutoff - 0.6, cutoff + 0.1))
}

cat("Testing", length(manip_regions), "manipulation regions for", 
    ifelse(analysisGender == 'F', "women", "men"), "\n")
```

# Data Preparation

The analysis uses **simulated blood donation data** that replicates the structure of the original study. The simulated data is publicly available for demonstration purposes in the study since the original study data consists of confidential medical records.

```{r data_loading}
# Load simulated data from GitHub repository
# NOTE: This is simulated data, not the original confidential medical records
data_url <- "https://raw.githubusercontent.com/rajkumarkarthik/rdpartial-data/main/Rosenman.et.al.2025_simulated_data_all.csv"

cat("Loading simulated data from GitHub repository...\n")
raw <- read.csv(data_url)

# Extract and clean the relevant dataset
dat <- raw %>%
  filter(gender == analysisGender,
         hlevel >= 0, 
         hlevel <= cutoff_upper) %>%        # Restrict to analysis range
  mutate(
    hlevel = round(hlevel, 1),              # Round hemoglobin to nearest 0.1
    age    = ifelse(is.na(age), mean(age, na.rm = TRUE), age)  # Impute missing age
  )

# Additional filtering for male analysis (exclude plasma donations)
if(analysisGender == 'M') {
  dat <- dat %>%
    filter(donationtype != 'Plasma')
}

# For time-to-next-donation outcome, filter to those with valid follow-up
if (outcome_col == "Ndaytonextdonation") {
  dat <- dat %>%
    filter(!is.na(Ndaytonextdonation), !is.infinite(Ndaytonextdonation))
}

cat("Analysis dataset: ", nrow(dat), "observations\n")
cat("Outcome variable:", outcome_col, "\n")
cat("Treatment variable:", treatment_col, "\n")
```

# Data Preprocessing

The analysis requires constructing a histogram of the running variable and computing tricubic kernel weights for local polynomial estimation.

```{r preliminaries}
# Create histogram for density estimation
hist_df <- dat %>%
  count(hlevel, name = "freq") %>%
  arrange(hlevel) %>%
  rename(x = hlevel)

cat("Histogram created with", nrow(hist_df), "unique hemoglobin values\n")

# Compute tricubic kernel weights
# These weights give more influence to observations closer to the cutoff
ix_left   <- dat$hlevel < cutoff
ix_right  <- !ix_left

w_kernel <- numeric(nrow(dat))
w_kernel[ix_left]  <- rdpartial:::.tricube(cutoff - dat$hlevel[ix_left])
w_kernel[ix_right] <- rdpartial:::.tricube(dat$hlevel[ix_right] - cutoff)

cat("Kernel weights computed for", sum(ix_left), "left-side and", 
    sum(ix_right), "right-side observations\n")
```

# Estimation

The estimation procedure tests each manipulation region, with automatic spline specification selection via cross-validation. Parallel processing is employed for computational efficiency.

```{r analysis_function}
# Analysis function for each manipulation region
analyze_region <- function(j, region, hist_df, dat, cutoff, num_folds, 
                          w_kernel, outcome_col, treatment_col, poly_order, 
                          treat_direction) {
  
  # Step 1: Estimate density under no manipulation assumption
  dens_out <- rdpartial:::.density_estimation(
    hist_df      = hist_df,
    manip_region = region,
    cutoff       = cutoff,
    knot_options = 3:8,
    mod_types    = "smooth",
    num_folds    = num_folds,
    make_plot    = FALSE
  )
  
  # Step 2: Compute partial identification bounds
  bnds <- rdpartial::bounds_fuzzy(
    x               = dat$hlevel,
    y               = dat[[outcome_col]],
    z               = dat[[treatment_col]],
    cutoff          = cutoff,
    true_counts     = dens_out$counts,
    weights         = w_kernel,
    poly_order      = poly_order,
    treat_direction = treat_direction,
    bounds          = "both",
    runVarPlots     = FALSE,
    ylab            = outcome_col,
    xlab            = "Hemoglobin Level (g/dL)"
  )
  
  list(
    region_id    = j,
    bounds       = bnds,
    avg_cv_sse   = dens_out$avg_cv_sse,
    avg_sse      = dens_out$avg_sse,
    knots        = dens_out$knots
  )
}

# Same analysis function but with plots enabled for optimal region
analyze_region_with_plots <- function(j, region, hist_df, dat, cutoff, num_folds, 
                                     w_kernel, outcome_col, treatment_col, poly_order, 
                                     treat_direction) {
  
  # Step 1: Estimate density (with plots)
  dens_out <- rdpartial:::.density_estimation(
    hist_df      = hist_df,
    manip_region = region,
    cutoff       = cutoff,
    knot_options = 3:8,
    mod_types    = "smooth",
    num_folds    = num_folds,
    make_plot    = TRUE
  )
  
  # Step 2: Compute bounds (with plots)
  bnds <- rdpartial::bounds_fuzzy(
    x               = dat$hlevel,
    y               = dat[[outcome_col]],
    z               = dat[[treatment_col]],
    cutoff          = cutoff,
    true_counts     = dens_out$counts,
    weights         = w_kernel,
    poly_order      = poly_order,
    treat_direction = treat_direction,
    bounds          = "both",
    runVarPlots     = TRUE,
    ylab            = outcome_col,
    xlab            = "Hemoglobin Level (g/dL)"
  )
  
  list(
    region_id    = j,
    bounds       = bnds,
    avg_cv_sse   = dens_out$avg_cv_sse,
    avg_sse      = dens_out$avg_sse,
    knots        = dens_out$knots,
    density_plot = dens_out$plot
  )
}
```

```{r parallel_analysis}
cat("Analyzing", length(manip_regions), "manipulation regions...\n\n")

start_time <- Sys.time()

# Run analysis across all manipulation regions  
results <- parallel::mclapply(seq_along(manip_regions), function(j) {
  analyze_region(j, manip_regions[[j]], hist_df, dat, cutoff, num_folds, 
                w_kernel, outcome_col, treatment_col, poly_order, treat_direction)
}, mc.cores = n_cores)

end_time <- Sys.time()
cat(sprintf("Analysis completed in %.2f minutes\n", 
           as.numeric(difftime(end_time, start_time, units = "mins"))))
```

# Results

The following sections present bounds estimates across manipulation regions and identify the optimal specification based on cross-validation performance.

```{r results_summary}
# Extract bounds matrix - handle simplified bounds structure
bounds_mat <- do.call(rbind, lapply(results, function(x) x$bounds))
rownames(bounds_mat) <- paste0("R", seq_along(manip_regions))

cat("Partial-identification bounds across manipulation regions:\n")
print(round(bounds_mat, 4))

# Extract model selection diagnostics  
sse_tbl <- do.call(rbind, lapply(results, function(x)
  c(cv_sse = x$avg_cv_sse, sse = x$avg_sse, knots = x$knots)))
rownames(sse_tbl) <- paste0("R", seq_along(manip_regions))

cat("\nSpline cross-validation diagnostics:\n")
print(round(sse_tbl, 4))

# Identify optimal manipulation region (lowest cross-validation error)
optIndex <- which.min(sse_tbl[, "cv_sse"])
opt_region <- manip_regions[[optIndex]]

cat(sprintf("\nOptimal manipulation region: R%d [%.2f, %.2f]\n", 
           optIndex, opt_region[1], opt_region[2]))
cat(sprintf("Cross-validation SSE: %.4f\n", sse_tbl[optIndex, "cv_sse"]))
cat(sprintf("Optimal bounds: [%.4f, %.4f]\n", 
           bounds_mat[optIndex, "lower"], bounds_mat[optIndex, "upper"]))

# Generate plots only for optimal region to save memory during parallel processing
cat("\nGenerating diagnostic plots for optimal region...\n")
opt_results <- analyze_region_with_plots(optIndex, opt_region, hist_df, dat, cutoff, 
                                        num_folds, w_kernel, outcome_col, treatment_col, 
                                        poly_order, treat_direction)
```

# Visualization

The package generates diagnostic plots for density estimation, outcome analysis, and treatment assignment patterns.

```{r plots, fig.width=10, fig.height=12}
# Plot density estimation for optimal region
density_plot <- opt_results$density_plot +
  ggtitle(paste0('Density Estimation - Optimal Manipulation Region for ',
                ifelse(analysisGender == 'F', "Women", "Men"), 
                ': [', paste(round(opt_region, 2), collapse = ', '), ']')) +
  theme_minimal()

print(density_plot)

# Plot outcome variable
outcome_plot <- opt_results$bounds$yPlot +
  ggtitle("Outcome Analysis: Return Probability vs. Hemoglobin Level") +
  theme_minimal()

print(outcome_plot)

# Plot treatment variable  
treatment_plot <- opt_results$bounds$zPlot +
  ggtitle("Treatment Analysis: Acceptance Probability vs. Hemoglobin Level") +
  theme_minimal()

print(treatment_plot)
```

# Bootstrap Inference

```{r bootstrap_check}
# Bootstrap analysis (skipped in CI to avoid timeouts)
if (identical(Sys.getenv("CI"), "true")) {
  cat("Bootstrap analysis skipped in CI - run locally for confidence intervals.\n")
} else {
  cat("Computing bootstrap confidence intervals...\n")
}
```

```{r bootstrap_setup, eval = !identical(Sys.getenv("CI"), "true")}
# Bootstrap confidence intervals with 100 replications
n_boot <- 100
cat(sprintf("Running %d bootstrap replications (this may take several minutes)...\n", n_boot))
```

```{r bootstrap_analysis, eval = !identical(Sys.getenv("CI"), "true")}
start_boot_time <- Sys.time()

# Bootstrap confidence intervals 
bootBounds <- rdpartial::bootstrap_bounds(
  data            = dat,
  running_var     = 'hlevel',
  outcome         = outcome_col,
  treatment       = treatment_col,
  cutoff          = cutoff,
  manip_regions   = manip_regions,
  estimator       = 'fuzzy',
  n_boot          = n_boot,
  parallel        = TRUE,
  n_cores         = n_cores,
  seed            = 2021
)

end_boot_time <- Sys.time()
boot_duration <- as.numeric(difftime(end_boot_time, start_boot_time, units = "mins"))
cat(sprintf("Bootstrap completed in %.2f minutes\n", boot_duration))
```

```{r bootstrap_results, eval = !identical(Sys.getenv("CI"), "true")}
# Display bootstrap confidence intervals
cat("Bootstrap 95% Confidence Intervals:\n")
print(bootBounds)

# Enhanced results summary
cat("\nDetailed Bootstrap Results Summary:\n")
cat("====================================\n")

ci_matrix <- bootBounds$ci
for(i in seq_len(nrow(ci_matrix))) {
  region <- manip_regions[[i]]
  cat(sprintf("Region %d [%.2f, %.2f]: CI = [%.4f, %.4f], Width = %.4f\n",
             i, region[1], region[2], 
             ci_matrix[i, "lwr"], ci_matrix[i, "upr"],
             ci_matrix[i, "upr"] - ci_matrix[i, "lwr"]))
}

# Highlight optimal region results
opt_ci <- ci_matrix[optIndex, ]
cat(sprintf("\nOptimal Region Results (R%d):\n", optIndex))
cat(sprintf("• Manipulation interval: [%.2f, %.2f] g/dL\n", opt_region[1], opt_region[2]))
cat(sprintf("• Point bounds: [%.4f, %.4f]\n", 
           bounds_mat[optIndex, "lower"], bounds_mat[optIndex, "upper"]))
cat(sprintf("• 95%% CI: [%.4f, %.4f]\n", opt_ci["lwr"], opt_ci["upr"]))
cat(sprintf("• CI width: %.4f\n", opt_ci["upr"] - opt_ci["lwr"]))
```

# Implementation Notes

## Bounds Interpretation

The bounds matrix contains the range of plausible treatment effects under each manipulation scenario:

```{r example_interpretation, eval=FALSE && !identical(Sys.getenv("CI"), "true")}
# The bounds tell us the range of plausible effects
print(bounds_mat[optIndex, ])

# Bootstrap confidence intervals add uncertainty quantification
print(bootBounds$ci[optIndex, ])
```

Tight bounds excluding zero indicate robust identification of treatment effect direction and magnitude. Wide bounds or bounds including zero suggest substantial manipulation uncertainty or limited identification power.

## Parameter Selection

**Manipulation regions**: Specify intervals based on institutional knowledge of manipulation possibilities. Multiple specifications should be tested for robustness assessment.

**Computational parameters**: The `n_boot` parameter controls bootstrap replications (100-500 recommended), `knot_options` determines spline flexibility (3:8 typically sufficient), and `parallel` enables multicore processing on Unix systems.

**Data requirements**: The package expects numeric running variables, binary outcomes (0/1) for standard applications, and binary treatment indicators (0/1). Missing values should be handled prior to analysis.

# Performance

```{r performance_summary}
cat("Performance Summary:\n")
cat("===================\n")
cat(sprintf("Analysis duration: %.2f minutes\n", 
           as.numeric(difftime(end_time, start_time, units = "mins"))))

# Show bootstrap info only if it ran
if (!identical(Sys.getenv("CI"), "true")) {
  cat(sprintf("Bootstrap duration: %.2f minutes\n", boot_duration))  
  cat(sprintf("Bootstrap replications: %d\n", n_boot))
}

cat(sprintf("Parallel cores used: %d\n", n_cores))
cat(sprintf("Manipulation regions tested: %d\n", length(manip_regions)))
```

# Summary

This vignette demonstrates `rdpartial` package functionality for regression discontinuity designs with manipulation concerns. The package provides robust bounds estimation through density estimation, cross-validated model selection, and bootstrap inference. Key methodological features include explicit manipulation modeling, automatic spline specification selection, and parallel computational implementation.

# References

For more details on the theoretical foundations, see @rosenman2025donorsdeferralreturnbehavior. The package documentation provides additional technical details and examples for various use cases.
